{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["PUxdctIdxU6B","UPMDlF4mjG6v"]},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.13"}},"cells":[{"cell_type":"markdown","metadata":{"id":"PUxdctIdxU6B"},"source":["---\n","---\n","Problem Set 3: Regular Expressions\n","\n","Applied Data Science using Python\n","\n","New York University, Abu Dhabi\n","\n","Out: 20th Sept 2023 || **Due: 27th Sept 2023 at 23:59**\n","\n","---\n","---\n","#Start Here\n","## Learning Goals\n","### General Goals\n","- Learn the basics of text processing\n","- Learn the basics of regular expressions\n","\n","### Specific Goals\n","- Learn basic regex functions and operators\n","- Learn patterns and character classes\n","- Learn how to use quantifiers\n","- Learn how to use groups\n","- Learn about look-ahead and look-behind matching\n","\n","## Collaboration Policy\n","- You are allowed to talk with / work with other students on homework assignments.\n","- You can share ideas but not code, analyses or results; you must submit your own code and results. All submitted code will be compared against all code submitted this and previous semesters and online using MOSS. We will also critically analyze the similarities in the submitted reports, methodologies, and results, **but we will not police you**. We expect you all to be mature and responsible enough to finish your work with full integrity.\n","- You are expected to comply with the [University Policy on Academic Integrity and Plagiarism](https://www.nyu.edu/about/policies-guidelines-compliance/policies-and-guidelines/academic-integrity-for-students-at-nyu.html). Violations may result in penalties, such as failure in a particular assignment.\n","\n","## Late Submission Policy\n","You can submit the homework for upto 3 late days. However, we will deduct **20 points** from your homework grade **for each late day you take**. We will not accept the homework after 3 late days.\n","\n","## Distribution of Class Materials\n","These problem sets and recitations are intellectual property of NYUAD, and we request the students to **not** distribute them or their solutions to other students who have not signed up for this class, and/or intend to sign up in the future. We also request you don't post these problem sets, and recitations online or on any public platforms.\n","\n","## Disclaimer\n","The number of points do not necessarily signify/correlate to the difficulty level of the tasks.\n","\n","## Submission\n","You will submit all your code as a Python Notebook through [Brightspace](https://brightspace.nyu.edu/).\n","\n","---\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"UPMDlF4mjG6v"},"source":["# General Instructions\n","This homework is worth 100 points. It has 2 parts. Below each part, we provide a set of concepts required to complete that part. All the parts need to be completed in a Jupyter (Colab) Notebook attached with this handout. We recommend that you read the complete handout before starting the homework.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3SWf22cCjQNY"},"source":["# Part I: He Who Must Not Be Named (40 points)\n","\n","The year is 1988. Your name is Barnabas Cuffe. You live in Great Britain and work for the **Ministry of Magic**. You have been assigned the important task of making sure that the wizarding newspaper called the **Daily Prophet** only reports stories that comply with the rules of the Ministry of Magic.\n","\n","It has come to the Minister's attention that the upcoming issue of the Daily Prophet, makes several references to the **Unspeakables** -- *people who should not be named*.\n","\n","Your job is to wipe out the names of the Unspeakables and anonymize them, replacing them with the Ministry's preferred name, **John Smith**.\n","\n","There are far too many articles in this issue for the number of employees in the Ministry of Magic to manually comb over and make the relevant adjustments. The Ministry would like to write a program to do this automatically.\n"]},{"cell_type":"markdown","metadata":{"id":"p3VX4KB7zq2S"},"source":["## Example\n","\n","Suppose we have a segment of text as follows, where the name `Gareth Greengrass` is one of the *Unspeakables*, and hence is on the banned list:\n","\n","`I believe that Gareth Greengrass is an amazing golfer. Gareth Greengrass’ abilities are far beyond my own. My favorite golfer is Gareth Greengrass, and I have a shirt with GARETH GREENGRASS printed on it.\n","The article named Gareth-Greengrass was published yesterday. Greengrass is a service that extends Amazon Web Services functionality to Internet of Things.`\n","\n","After careful processing by your program, this segment should read:\n","\n","`I believe that John Smith is an amazing golfer. John Smith’ abilities are far beyond my own. My favorite golfer is John Smith, and I have a shirt with GARETH GREENGRASS printed on it.\n","The article named Gareth-Greengrass was published yesterday. Smith is a service that extends Amazon Web Services functionality to Internet of Things.`\n"]},{"cell_type":"markdown","metadata":{"id":"wfGNVsfFlYHV"},"source":["## Prompt\n","\n","Implement the function `clean` that takes in three arguments: a `list` of banned full names, a `list` of banned last names, and an input `string` to process. It should return as output the input string after the replacement of the banned full names and last names, if any.\n","\n","Specifically, the function should:\n","\n","1. Replace all instances of the banned full names with the officially approved name `John Smith`.\n","2. Replace all banned last names with the officially approved last name `Smith`.\n","\n","Your implementation will be run against a variety of test cases that will look at normal and edge case behavior of your code. It it thus important that you implement specifically what is necessary, not more or less.\n","\n","### Some clarifications:\n","\n","1. *Full name definition*: An instance of a full name always consists of two words, separated only by some whitespace. Each word must be properly capitalized (first letter of each word should be capitalized, the rest should be lower caps) for it to be a full name. Similarly, an instance of a last name is always a single word that is properly capitalized.\n","\n","2. *Other libraries*: You should not need to use any libraries other than the standard Python libraries.\n","\n","3. *Regex vs. other methods*: You are required to implement a Regex based solution to this problem.\n","\n","4. *Whitespace*: Your solution should preserve the original whitespace in the input source, if any. Do not add, remove, or replace any whitespace.\n","\n","5. *Can a last name be a first name?*: Yes, but you should prioritize full name replacement over last name replacement if possible.\n","\n","6. *Is that (e.g. Greengrass) a last name or something else?* - You have no way of knowing at this point, so if it looks like a last name, it is a last name. Replace it.\n","\n","7. *Helper Functions*: You can write helper functions if you'd like.\n","\n","8. We highly recommend you read this [documentation](https://docs.python.org/3.6/library/re.html) before attempting this part especially functions such as `re.sub()` and `re.compile()`.\n"]},{"cell_type":"code","metadata":{"id":"5lHr1i-Eq2ID","executionInfo":{"status":"ok","timestamp":1695659177332,"user_tz":-240,"elapsed":632,"user":{"displayName":"Yujia Wang","userId":"14813603275147341605"}}},"source":["import re\n","\n","def clean(banned_fn_lst, banned_ln_lst, input_text):\n","\n","  \"\"\"You can assume that list of last names is the set of unique last names derived\n","  from the list of full names i.e.\n","  banned_ln_lst = list(set([s.split()[-1] for s in full_names]))\n","\n","  :param banned_fn_lst: list of censored full names to be replaced\n","  :param banned_ln_lst: list of censored last names to be replaced\n","  :param input_text: input text to process\n","  :returns clean_str: output text with censored full names and last names removed\n","  \"\"\"\n","\n","  clean_str = \"\" #output string that will have the names replaced with John Smith\n","\n","  # Ministry approved full name and last name for your use to replace names with\n","  replacement_full_name = \"John Smith\"\n","  replacement_last_name = \"Smith\"\n","\n","  # Please write your implementation below this line\n","  ######### SOLUTION #########\n","\n","  ######### SOLUTION END #########\n","\n","  return clean_str"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"WB476gRqDgLy"},"source":["# Example of how we will call your function with different input/output pairs\n","# Example pair 1\n","# Given input\n","input_text = \"I believe that Gareth Greengrass is an amazing golfer. Gareth Greengrass' \"\\\n","      \"abilities are far beyond my own. My favorite golfer is Gareth Greengrass, \"\\\n","      \"and I have a shirt with GARETH GREENGRASS printed on it. The article named \"\\\n","      \"Gareth-Greengrass was published yesterday. Greengrass is a service that extends \"\\\n","      \"Amazon Web Services functionality to Internet of Things.\"\n","\n","# Expected output\n","output_text = \"I believe that John Smith is an amazing golfer. John Smith' \"\\\n","      \"abilities are far beyond my own. My favorite golfer is John Smith, \"\\\n","      \"and I have a shirt with GARETH GREENGRASS printed on it. The article named \"\\\n","      \"Gareth-Greengrass was published yesterday. Smith is a service that extends \"\\\n","      \"Amazon Web Services functionality to Internet of Things.\"\n","\n","# Example pair 2\n","# Given input\n","input_text2 = \"Samuel Jones was a tall man, but not in an unreachable way. Jones used to play poker in an inn near his house. \"\\\n","        \"Samuel was so famous, that the inn had a wall with SAMUEL-JONES painted on it. Jones' favourite drink was bourbon on the rocks.\"\n","\n","# Expected output\n","output_text2 = \"John Smith was a tall man, but not in an unreachable way. Smith used to play poker in an inn near his house. \"\\\n","            \"Samuel was so famous, that the inn had a wall with SAMUEL-JONES painted on it. Smith' favourite drink was bourbon on the rocks.\"\n","\n","# If your implementation is correct, this line should not give any error\n","assert(clean([\"Gareth Greengrass\"],[\"Greengrass\"],input_text) == output_text)\n","assert(clean([\"Samuel Jones\"],[\"Jones\"],input_text2) == output_text2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"goGyqP7dnRhU"},"source":["## *Concepts required to complete this task*\n","\n","*   Regex Groups\n","*   Regex Quantifiers\n","*   Regex Set Operator\n","*   Regex Anchors\n","*   Optionally `re.compile()`\n","*   Optionally `re.sub()`\n","*   Optionally `map()` function\n","*   Optionally `lambda` functions"]},{"cell_type":"markdown","metadata":{"id":"GPMRZZxgUMSd"},"source":["## Rubric\n","\n","- +30 points for correctness (proper usage of regex library to achieve the desired output)\n","- +5 points for conciseness (code and the regex usage is concise)\n","- +5 points for proper comments and variable names"]},{"cell_type":"markdown","metadata":{"id":"IuRYqcxmn4vS"},"source":["# Part II: Data Exploration: Analyzing COVID-19 Misinformation On Twitter (60 points)\n","\n","With the emergence of COVID-19 pandemic, the political and medical misinformation elevated to create what was being commonly referred to as the global **infodemic**. A huge chunk of the false information on COVID-19 was spread via Twitter. In this part you will use your knowledge of regular expressions to explore the Twitter data on COVID-19 discourse.\n","\n","Before we describe the prompt, let us look at the data.\n"]},{"cell_type":"code","metadata":{"id":"u-XAnfAeASTi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695659189272,"user_tz":-240,"elapsed":2621,"user":{"displayName":"Yujia Wang","userId":"14813603275147341605"}},"outputId":"6779e1af-7e12-44ee-d5d6-7ee58ec04e8b"},"source":["# Loading the dataset\n","\n","# In Google colab, you need to mount your drive to be access your files. If you are running jupyter notebook locally no need to do this step.\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"9ZUNbl7yB1Md"},"source":["# Let us now read the tweets as list of lines\n","path = \"/content/drive/My Drive/Fall 2023/Applied Data Science/Dataset/PS3_covid19_misinformation_data.txt\" # edit the path to your folder containing the data file\n","tweets = \"\"\n","with open(path,\"r\") as file:\n","    # we'll read that into a variable called tweets\n","    tweets=file.readlines()\n","\n","# If you want you can look at the tweets by uncommenting the following line\n","tweets"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"On5Ta8bYGYm0"},"source":["The data we are working with has 4573 tweets with each line having a username, datetime, tweet, bot probability, and category class, all separated by a whitespace character, two pipes `||`, and another whitespace character. Let's look at an example line from the file above to understand this better:\n","\n","`twitmo20 || Tue Jul 07 19:19:40 +0000 2020 || Imagine you are a Democratic and were told that COVID is a Bioweapon used on the people in another attempt to destr… https://t.co/JJpXaIqRt8 || 0.7716583196 || politics`\n","\n","In the above line `twitmo20` is the **username** of the user who tweeted this tweet, `Tue Jul 07 19:19:40 +0000 2020` is the **date and time** of this tweet, `Imagine you are a Democratic and were told that COVID is a Bioweapon used on the people in another attempt to destr… https://t.co/JJpXaIqRt8` is the **tweet** text itself, **0.7716583196** is the probability that this tweet was by a **bot**  *(>0.7716.. signifies that there is more than 77% probability that this is a bot account)*, and finally `politics` means this tweet has been **categorized** or **annotated** as a political tweet.\n","\n","Now that we have read the data for you above, we would like to explore it, and that is what we will do in the next 3 parts."]},{"cell_type":"markdown","metadata":{"id":"lV9TKQoByaD2"},"source":["## Prompt"]},{"cell_type":"markdown","metadata":{"id":"8_oQXfHKSvfh"},"source":["### A. Exploring categories (20 points)\n","\n","In the above example, we saw that the tweet was categorized as a `politics` tweet. That is, however, not the only category in our dataset. Use your knowledge of regular expressions to extract all the different categories in the dataset, along with the distribution of the categories.\n","\n","More precisely, write a function called `categories_to_counts(tweets)` that takes in the list of tweet text above, and returns a dictionary with `category` as the key and `count` as value.\n","\n","For example, if your dataset had only two categories (`politics` and `conspiracy`) with two tweets categorized as `politics` and three tweets categorized as `conspiracy`, then your function should return `{'politics': 2, 'conspiracy': 3}` as output.\n","\n","Tip: You may find the `collections` library useful to count, so we have imported that for you."]},{"cell_type":"code","metadata":{"id":"jrHEurDKzb3p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695658246701,"user_tz":-240,"elapsed":463,"user":{"displayName":"Yujia Wang","userId":"14813603275147341605"}},"outputId":"5289568c-a146-4f71-d4e1-6efeadf5e152"},"source":["from collections import Counter\n","import re\n","def categories_to_counts(tweets):\n","  category_to_count_dict = {}\n","\n","  # Please write your implementation below this line\n","  ######### SOLUTION #########\n","\n","# adding import re at the beginning\n","\n","  # \\|\\| matches ||\n","  # [a-zA-Z]+ matches all the lower and upper letters and they can appear more than once\n","  # $ matches the element must be at the end of a line\n","  pattern = r'\\|\\| ([a-zA-Z]+)$'\n","\n","  # using a loop to check every line in the dataset\n","  for tweet in tweets:\n","    # using re.search() to find the element that satifies the pattern above in every tweet in the dataset\n","    category_element = re.search(pattern, tweet)\n","    if category_element:\n","      # group: (optional) group defaults to zero (meaning that it it will return the complete matched string).\n","      # it returns -1 if group exists but did not contribute to the match.\n","      category = category_element.group(1)\n","      # checking if the category exists\n","      # if it exists, the category_to_count_dict will count 1\n","      # if not exists, the category_to_count_dict will remain the same\n","      category_to_count_dict[category] = category_to_count_dict.get(category,0)+1\n","  ######### SOLUTION END #########\n","\n","  return category_to_count_dict\n","\n","# This is how we will call your function\n","c2c_dict = categories_to_counts(tweets)\n","\n","c2c_dict"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'irrelevant': 131,\n"," 'politics': 512,\n"," 'news': 95,\n"," 'conspiracy': 924,\n"," 'emergency': 17}"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"vLUa6p86XN1L"},"source":["Just for fun, run this code to actually look at the distribution of your data categories as a pie chart to understand your data better."]},{"cell_type":"code","metadata":{"id":"uq3DblV7XfCu"},"source":["# importing appropriate libraries\n","from matplotlib import pyplot as plt\n","\n","def create_pie_chart(counts_dictionary):\n","  # Creating a plot\n","  fig = plt.figure(figsize =(15, 15))\n","  data = counts_dictionary.values()\n","  categories = counts_dictionary.keys()\n","  plt.pie(data, labels = categories, autopct='%1.0f%%')\n","  # Displaying the plot\n","  plt.show()\n","\n","create_pie_chart(c2c_dict)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_eedG9AAUVD0"},"source":["#### Rubric\n","\n","- +12 points for correctness\n","- +5 points for conciseness\n","- +3 points for proper comments and variable names"]},{"cell_type":"markdown","metadata":{"id":"l8B-ML5SYXTa"},"source":["### B. Exploring hashtag distribution in informed and misinformed users (20 points)\n","\n","Within the COVID-19 discourse, there are two kinds of users, **informed** users, and **misinformed** users. Informed users are the ones that have tweets in the categores of `calling out or correction`, `true prevention`, `true public health response`, and `sarcasm or satire`. These are users who post true and useful information, and call out or make fun of misinformation. Unfortunately, there is also a huge chunk of misinformed users. These are tweeters who tweet about `conspiracy`, `false fact or prevention`, `fake cure`, `fake treatment`, and `false public health response`. Basically, these are users who are responsible for spreading misinformation.\n","\n","We would like to know that on average how many hashtags do informed users use, and how many hashtags do misinformed users use.\n","\n","More concretely, complete the function `average_hashtags_per_class(tweets)` that takes in the `tweets` and prints the average number of hashtags used by informed as well as misinformed users.\n","\n"]},{"cell_type":"code","metadata":{"id":"jRQl6ZeKbTud","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695663172452,"user_tz":-240,"elapsed":409,"user":{"displayName":"Yujia Wang","userId":"14813603275147341605"}},"outputId":"5c4954b0-53ed-4845-93e7-8e28bf540be6"},"source":["import re\n","\n","def average_hashtags_per_class(tweets):\n","\n","  informed_categories = ['calling out or correction', 'true prevention', 'true public health response', 'sarcasm or satire']\n","  misinformed_categories = ['conspiracy', 'false fact or prevention', 'fake cure', 'fake treatment', 'false public health response']\n","\n","  average_hashtags_informed = 0\n","  average_hashtags_misinformed = 0\n","\n","  # Please write your implementation below this line\n","  ######### SOLUTION #########\n","\n","  # intializing the counts on the tweets\n","  count_informed = 0\n","  count_misinformed = 0\n","\n","  # matching the hashtags' pattern\n","  pattern_hashtag = r'#\\w+'\n","\n","  # using a loop to check the hashtags through the tweets\n","  for tweet in tweets:\n","    # seperating the tweets based on ||\n","    seperate_tweet = tweet.split(' || ')\n","\n","    # checking if the tweets have 5 elements (username, date and toime, tweet text, bot, category)\n","    if len(seperate_tweet) >= 5:\n","      # finding and extracting the tweet_text and category parts\n","      tweet_text = seperate_tweet[2]\n","      category = seperate_tweet[4]\n","      # finding all the hashtags in the tweet_text\n","      hashtags = re.findall(pattern_hashtag, tweet_text)\n","\n","      # checking if the category in the informed_categories\n","      # and if it has hashtags\n","      # strip(): removes any leading, and trailing whitespaces\n","      if category.strip() in informed_categories and hashtags:\n","        # adding the count of tweets in the hashtags\n","        average_hashtags_informed += len(hashtags)\n","        # every tweet in the informed_categories, whether or not there is a hashtag,\n","        # adding 1 to the count_informed\n","        count_informed += 1\n","\n","      # same thing for the misinformed_categories\n","      elif category.strip() in misinformed_categories and hashtags:\n","        average_hashtags_misinformed += len(hashtags)\n","        count_misinformed += 1\n","\n","  # calculating the average of count_informed and count_misinformed\n","  # using average/= count to verify there is no 0\n","  if count_informed > 0:\n","    average_hashtags_informed /= count_informed\n","  if count_misinformed > 0:\n","    average_hashtags_misinformed /= count_misinformed\n","\n","  ######### SOLUTION END #########\n","\n","  # Printing average values\n","  print(\"Informed users use %f hashtags on average in a tweet\"%average_hashtags_informed)\n","  print(\"Misinformed users use %f hashtags on average in a tweet\"%average_hashtags_misinformed)\n","\n","average_hashtags_per_class(tweets)"],"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Informed users use 1.674468 hashtags on average in a tweet\n","Misinformed users use 2.860566 hashtags on average in a tweet\n"]}]},{"cell_type":"markdown","metadata":{"id":"SjHohhXeUaUG"},"source":["#### Rubric\n","\n","- +12 points for correctness\n","- +5 points for conciseness\n","- +3 points for proper comments and variable names"]},{"cell_type":"markdown","metadata":{"id":"PO_q_mh0mYsi"},"source":["### C. Retrieving bot accounts (20 points)\n","\n","For each username in our dataset, we have an assigned bot probability. For this task, we would like to print the usernames of all the users that are bots, and also their bot probabilities. Particularly, we would like to print the usernames and bot probabilities of each user if they have a bot probability of greater than `0.70`.\n","\n","Write a regex pattern that takes in a tweet text as above, and prints in the following format:\n","\n","`{'username': '1055WERC', 'botprob': '0.7819662242'}`\n","\n","`{'username': 'Atho_1982', 'botprob': '0.8633729135'}`\n","\n","`{'username': 'interaksyon', 'botprob': '0.97794317549999995'}`\n","\n","...\n","\n","We have already provided you with the code. All you need to do is write the regex pattern and assign it to the variable `pattern`.\n","\n","Notes:\n","\n","1. You are not allowed to change the code below.\n","2. Please read and play with the code below to understand what it is doing.\n","3. You are not allowed to use `.split()` function."]},{"cell_type":"code","metadata":{"id":"ZQMpD4OV2N9f","executionInfo":{"status":"ok","timestamp":1695666363739,"user_tz":-240,"elapsed":613,"user":{"displayName":"Yujia Wang","userId":"14813603275147341605"}}},"source":["def get_bot_accounts(tweet, pattern):\n","  \"\"\"\n","  This function takes in a tweet and a pattern and prints the output\n","  as described above\n","  \"\"\"\n","  for item in re.finditer(pattern,tweet):\n","    print(item.groupdict())\n","\n","######### SOLUTION #########\n","pattern = r'\\|\\| (\\w+) \\|\\| [^|]+ \\|\\| [^|]+ \\|\\| ([0-9.]+) \\|\\|'\n","######### SOLUTION END #########\n","\n","for tweet in tweets:\n","  get_bot_accounts(tweet.rstrip(), pattern)"],"execution_count":54,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7FDsTpQUUfUf"},"source":["#### Rubric\n","\n","- +12 points for correctness\n","- +5 points for conciseness\n","- +3 points for proper comments and variable names"]},{"cell_type":"markdown","metadata":{"id":"N08hHBwwoHHT"},"source":["## *Concepts required to complete this task*\n","\n","*   Regex Groups\n","*   Regex Quantifiers\n","*   Regex Set Operator\n","*   Regex Anchors"]},{"cell_type":"markdown","metadata":{"id":"O8u65HQDHSmu"},"source":["# Concluding Remarks\n","\n","In this homework we have tried to push you to use regular expressions for all your solutions. This is for learning purposes. This does not necessarily imply that regular expressions always produce the most robust and ideal solutions. While regular expressions are very useful in certain cases, there is typically more than one way to achieve the same results using different methodologies. In fact in many problems it may be just easier to not use regular expressions at all. This is all dependent on the given problem, and how the relevant dataset is formatted. At the end of this course, you will hopefully get better at learning the best methodology to use for the problem at hand.\n"]}]}